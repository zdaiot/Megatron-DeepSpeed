{
    // 使用 IntelliSense 了解相关属性。 
    // 悬停以查看现有属性的描述。
    // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python: Debug DeepSpeed",
            "type": "python",
            "request": "launch",
            "program": "~/.conda/envs/mdm310/bin/deepspeed",
            "justMyCode": false,
            "console": "integratedTerminal",
            "args": [
                "/mnt/private_zhaodali_cq/llm_install/Megatron-DeepSpeed-Microsoft/pretrain_gpt.py",
                // "${file}",
                "--override-opt_param-scheduler",
                "--adam-beta1", "0.9",
                "--adam-beta2", "0.95",
                "--tensor-model-parallel-size", "2",
                "--init-method-std", "0.02",
                "--lr-decay-tokens", "300000000000",
                "--lr-warmup-tokens", "3000000000",
                "--micro-batch-size", "2",
                "--exit-duration-in-mins", "30000000",
                "--global-batch-size", "256",
                "--num-layers", "12",
                "--hidden-size", "768",
                "--num-attention-heads", "12",
                "--seq-length", "2048",
                "--max-position-embeddings", "2048",
                "--train-tokens", "300000000000",
                "--train-samples", "292968750",
                "--lr", "6.0e-4",
                "--min-lr", "1.0e-6",
                "--lr-decay-style", "cosine",
                "--split", "949,50,1",
                "--log-interval", "10",
                "--eval-interval", "100",
                "--eval-iters", "10",
                "--save-interval", "100",
                "--weight-decay", "0.1",
                "--clip-grad", "1.0",
                "--hysteresis", "2",
                "--num-workers", "0",
                "--fp16",
                "--seed", "1234",
                "--load", "output/checkpoint/gpt_0.125B_tok300B_lr6.0e-4_min1.0e-6_w3000M_d300B_cosine_gbs256_mbs2_g8_z1_mp2_pp2_seed1234_rebase",
                "--save", "output/checkpoint/gpt_0.125B_tok300B_lr6.0e-4_min1.0e-6_w3000M_d300B_cosine_gbs256_mbs2_g8_z1_mp2_pp2_seed1234_rebase",
                "--no-async-tensor-model-parallel-allreduce",
                "--tensorboard-queue-size", "1",
                "--log-timers-to-tensorboard",
                "--log-batch-size-to-tensorboard",
                "--log-validation-ppl-to-tensorboard",
                "--tensorboard-dir", "output/tensorboard/gpt_0.125B_tok300B_lr6.0e-4_min1.0e-6_w3000M_d300B_cosine_gbs256_mbs2_g8_z1_mp2_pp2_seed1234_rebase_90bb2f79-0654-4b76-a903-9a10ca0d5ab0_2023.12.07_18.37.20",
                "--checkpoint-activations",
                "--log-optimizer-states-to-tensorboard",
                "--vocab-file", "/mnt/private_zhaodali_cq/llm_install/Megatron-DeepSpeed-Microsoft/examples_deepspeed/rebase/data/gpt2-vocab.json",
                "--merge-file", "/mnt/private_zhaodali_cq/llm_install/Megatron-DeepSpeed-Microsoft/examples_deepspeed/rebase/data/gpt2-merges.txt",
                "--data-path", "/mnt/private_zhaodali_cq/llm_install/Megatron-DeepSpeed-Microsoft/examples_deepspeed/rebase/data/oscar-en-10k_text_document",
                "--data-impl", "mmap",
                "--deepspeed",
                "--deepspeed_config", "/mnt/private_zhaodali_cq/llm_install/Megatron-DeepSpeed-Microsoft/examples_deepspeed/rebase/ds_config_gbs256_mbs2_log10_zero1.json",
                "--zero-stage", "1",
                "--pipeline-model-parallel-size", "2",
            ],
            "env": {"PYTHONPATH": "${workspaceFolder}${pathSeparator}${env:PYTHONPATH}:${workspaceFolder}/megatron${pathSeparator}${env:PYTHONPATH}"}
        },
    ]
}